import streamlit as st
import pandas as pd

scraped_data = pd.read_csv('data/processed/scraped_data.csv')
analysis_summary = pd.read_csv('data/processed/analysis_summary.csv')

st.title('ğŸ§  AnÃ¡lisis Inteligente de ArtÃ­culos sobre Productos Frescos')
st.markdown('ExtracciÃ³n automÃ¡tica de artÃ­culos + Resumen con IA')

st.sidebar.title('MenÃº de navegaciÃ³n')
seccion = st.sidebar.radio(
    'Ir a:',
    [
        'ğŸ¯ Objetivos del Proyecto',
        'ğŸ•¸ï¸ Parte 1: Web Scraping',
        'ğŸ¤– Parte 2: AnÃ¡lisis con IA',
        'ğŸ“Š Parte 3: Resultados y Ejemplos',
        'ğŸ“¥ Descarga de Archivos',
        'ğŸ› ï¸ TecnologÃ­as y Flujo',
    ],
)

if seccion == 'ğŸ¯ Objetivos del Proyecto':
    st.header('ğŸ¯ Objetivos del Proyecto')
    st.markdown("""
    El objetivo de este proyecto es automatizar la extracciÃ³n y anÃ¡lisis de contenido sobre la industria de productos frescos. Las fases clave son:

    1. **ExtracciÃ³n de artÃ­culos**: Scraping de artÃ­culos desde categorÃ­as como **Comercio Global**, **TecnologÃ­a** y **Seguridad Alimentaria**.
    2. **AnÃ¡lisis con IA**: Resumen automÃ¡tico y extracciÃ³n de temas clave usando un modelo de lenguaje.
    3. **VisualizaciÃ³n interactiva**: Mostrar los resultados de manera accesible en una interfaz visual.
    """)

elif seccion == 'ğŸ•¸ï¸ Parte 1: Web Scraping':
    st.header('ğŸ•¸ï¸ Parte 1: ExtracciÃ³n de ArtÃ­culos (Web Scraping)')
    st.markdown("""
    En esta fase, se recopilaron artÃ­culos de las siguientes categorÃ­as:
    - **Comercio Global**
    - **TecnologÃ­a**
    - **Seguridad Alimentaria**
    
    Utilizamos un **proceso de scraping en dos fases** para obtener:
    1. **Metadatos**: TÃ­tulos, descripciones, categorÃ­as y URLs.
    2. **Contenido Completo**: ArtÃ­culos completos de cada URL.
    """)
    st.dataframe(scraped_data)

elif seccion == 'ğŸ¤– Parte 2: AnÃ¡lisis con IA':
    st.header('ğŸ¤– Parte 2: Procesamiento de Texto con IA')
    st.markdown("""
    Cada artÃ­culo extraÃ­do fue procesado con un modelo de lenguaje para:
    - ğŸ“ **Generar un resumen** conciso del artÃ­culo.
    - ğŸ§© **Extraer temas clave** que describen el contenido.

    Esta informaciÃ³n se almacena en un archivo CSV que puedes explorar a continuaciÃ³n.
    """)
    st.dataframe(analysis_summary[['Title', 'Summary', 'Topics']])

elif seccion == 'ğŸ“Š Parte 3: Resultados y Ejemplos':
    st.header('ğŸ“Š Resultados Finales y Ejemplos de ArtÃ­culos')
    st.markdown("""
    AquÃ­ puedes ver un ejemplo de los artÃ­culos procesados junto con los resÃºmenes generados y los temas clave extraÃ­dos.
    """)

    for idx, row in analysis_summary.iterrows():
        st.subheader(f'ğŸ“° {row["Title"]}')
        st.markdown(f'ğŸ“‚ **CategorÃ­a:** {row["Category"]}')
        st.markdown(f'ğŸ”— **Enlace al artÃ­culo:** [Ver artÃ­culo]({row["URL"]})')
        st.markdown(f'ğŸ“ **Resumen:** {row["Summary"]}')
        st.markdown(f'ğŸ·ï¸ **Temas clave:** {row["Topics"]}')
        st.markdown('---')

elif seccion == 'ğŸ“¥ Descarga de Archivos':
    st.header('ğŸ“¥ Descarga de Archivos CSV')
    st.markdown("""
    Puedes descargar los archivos con los datos estructurados del proyecto:
    - **ArtÃ­culos extraÃ­dos** con metadatos y contenido completo.
    - **AnÃ¡lisis de IA** con resÃºmenes y temas clave generados por el modelo de lenguaje.
    """)
    st.download_button(
        'ğŸ“„ Descargar scraped_data.csv',
        scraped_data.to_csv(index=False),
        'scraped_data.csv',
        mime='text/csv',
    )
    st.download_button(
        'ğŸ“„ Descargar analysis_summary.csv',
        analysis_summary.to_csv(index=False),
        'analysis_summary.csv',
        mime='text/csv',
    )

elif seccion == 'ğŸ› ï¸ TecnologÃ­as y Flujo':
    st.header('ğŸ› ï¸ TecnologÃ­as Utilizadas y Flujo del Proyecto')
    st.markdown("""
    **TecnologÃ­as clave:**
    - **Python 3.12**: Lenguaje principal.
    - **Scrapy**: Framework de web scraping.
    - **LLM (DeepSeek)**: Modelo de lenguaje para anÃ¡lisis de contenido.
    - **Streamlit**: VisualizaciÃ³n interactiva de resultados.
    
    **Flujo del Proyecto:**
    1. **ExtracciÃ³n de datos** con Scrapy (fases de metadata y contenido completo).
    2. **AnÃ¡lisis de IA** usando un modelo de lenguaje para generar resÃºmenes y extraer temas.
    3. **VisualizaciÃ³n interactiva** de los resultados en Streamlit para una mejor comprensiÃ³n.
    """)

    st.image('assets/flow.png', caption='Flujo de trabajo del proyecto')
